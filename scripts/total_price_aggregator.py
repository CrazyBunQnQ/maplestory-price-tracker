#!/usr/bin/env python3
import json
import time
import os
from datetime import datetime, timedelta
from collections import deque
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class TotalPriceAggregator:
    def __init__(self, source_json_path="data/equipment_prices.json", 
                 history_dir="data/price_history"):
        self.source_json_path = source_json_path
        self.history_dir = history_dir
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(history_dir, exist_ok=True)
        
        # æ™‚é–“é–“éš”è¨­å®š
        self.price_intervals = {
            '1hour': {
                'interval': timedelta(hours=1),
                'maxlen': 168,  # 1é€±é–“åˆ†ï¼ˆ168æ™‚é–“ï¼‰
                'description': '1é€±é–“åˆ†ï¼ˆ1æ™‚é–“æ¯ï¼‰'
            },
            '12hour': {
                'interval': timedelta(hours=12),
                'maxlen': 60,   # 1ãƒ¶æœˆåˆ†ï¼ˆ60å› = 30æ—¥ï¼‰
                'description': '1ãƒ¶æœˆåˆ†ï¼ˆ12æ™‚é–“æ¯ï¼‰'
            },
            '1day': {
                'interval': timedelta(days=1),
                'maxlen': 365,  # 1å¹´åˆ†ï¼ˆ365æ—¥ï¼‰
                'description': '1å¹´åˆ†ï¼ˆ1æ—¥æ¯ï¼‰'
            }
        }
        
        # ç·ä¾¡æ ¼å±¥æ­´ã‚’ç®¡ç†
        self.total_price_history = {}
        
        self.initialize_total_price_history()
        self.load_existing_total_price_history()

    def initialize_total_price_history(self):
        """ç·ä¾¡æ ¼å±¥æ­´ã‚’åˆæœŸåŒ–"""
        for interval_type in self.price_intervals:
            self.total_price_history[interval_type] = deque(
                maxlen=self.price_intervals[interval_type]['maxlen']
            )
        logger.info("ç·ä¾¡æ ¼å±¥æ­´ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")

    def load_existing_total_price_history(self):
        """æ—¢å­˜ã®ç·ä¾¡æ ¼å±¥æ­´ã‚’èª­ã¿è¾¼ã¿"""
        try:
            for interval_type in self.price_intervals:
                total_file = os.path.join(self.history_dir, f"total_price_{interval_type}.json")
                if os.path.exists(total_file):
                    with open(total_file, 'r', encoding='utf-8') as f:
                        try:
                            data = json.load(f)
                            
                            if isinstance(data, list) and len(data) > 0:
                                valid_data = []
                                for point in data:
                                    if isinstance(point, dict) and 'timestamp' in point and 'total_price' in point:
                                        valid_data.append(point)
                                
                                if valid_data:
                                    self.total_price_history[interval_type] = deque(
                                        valid_data, 
                                        maxlen=self.price_intervals[interval_type]['maxlen']
                                    )
                                    logger.info(f"ç·ä¾¡æ ¼å±¥æ­´èª­ã¿è¾¼ã¿ {interval_type}: {len(valid_data)}ãƒ¬ã‚³ãƒ¼ãƒ‰")
                            else:
                                logger.info(f"ç·ä¾¡æ ¼å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ãŒç©º {interval_type}")
                        except json.JSONDecodeError as e:
                            logger.error(f"ç·ä¾¡æ ¼å±¥æ­´JSONèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {interval_type}: {e}")
                        except Exception as e:
                            logger.error(f"ç·ä¾¡æ ¼å±¥æ­´èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {interval_type}: {e}")
                else:
                    logger.info(f"ç·ä¾¡æ ¼å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ {interval_type}")
        except Exception as e:
            logger.error(f"ç·ä¾¡æ ¼å±¥æ­´èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    def should_update_total_price_interval(self, interval_type):
        """ç·ä¾¡æ ¼ã®æŒ‡å®šé–“éš”ã§ã®æ›´æ–°ãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯"""
        if interval_type not in self.total_price_history:
            return True
        
        history = self.total_price_history[interval_type]
        if not history:
            return True
        
        try:
            last_entry = history[-1]
            if not isinstance(last_entry, dict) or 'timestamp' not in last_entry:
                logger.warn(f"ç·ä¾¡æ ¼å±¥æ­´ãƒ‡ãƒ¼ã‚¿æ§‹é€ ä¸æ­£ {interval_type}: æ›´æ–°ãŒå¿…è¦")
                return True
                
            last_time = datetime.fromisoformat(last_entry['timestamp'].replace('Z', '+00:00'))
            now = datetime.now()
            
            required_interval = self.price_intervals[interval_type]['interval']
            time_diff = now - last_time
            
            logger.debug(f"ç·ä¾¡æ ¼é–“éš”ãƒã‚§ãƒƒã‚¯ {interval_type}: çµŒéæ™‚é–“={time_diff}, å¿…è¦é–“éš”={required_interval}")
            
            return time_diff >= required_interval
        except Exception as e:
            logger.error(f"ç·ä¾¡æ ¼é–“éš”æ›´æ–°ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼ ({interval_type}): {e}")
            return True

    def calculate_total_price_from_json(self):
        """JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç·ä¾¡æ ¼ã‚’è¨ˆç®—"""
        total_price = 0
        valid_items = 0
        invalid_items = 0
        
        try:
            if not os.path.exists(self.source_json_path):
                logger.error(f"ã‚½ãƒ¼ã‚¹JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.source_json_path}")
                return 0, 0
            
            with open(self.source_json_path, 'r', encoding='utf-8') as f:
                current_data = json.load(f)
            
            if not isinstance(current_data, dict):
                logger.error(f"JSONãƒ‡ãƒ¼ã‚¿ãŒè¾æ›¸å‹ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {type(current_data)}")
                return 0, 0
            
            for item_id, item_data in current_data.items():
                if not item_data or not isinstance(item_data, dict):
                    continue
                    
                if not item_data.get('item_name') or not item_data.get('item_price'):
                    continue
                
                try:
                    price_str = str(item_data['item_price']).replace(',', '').replace(' NESO', '').strip()
                    
                    # ç„¡åŠ¹ãªä¾¡æ ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
                    if price_str in ['æœªå–å¾—', 'undefined', '0', '', 'None']:
                        invalid_items += 1
                        continue
                        
                    current_price = int(price_str)
                    
                    # ç¾å®Ÿçš„ãªä¾¡æ ¼ç¯„å›²ãƒã‚§ãƒƒã‚¯ï¼ˆ1ä¸‡ï½1å„„NESOï¼‰
                    if 10000 <= current_price <= 100000000:
                        total_price += current_price
                        valid_items += 1
                    else:
                        logger.debug(f"ä¾¡æ ¼ç¯„å›²å¤– ({item_id}): {current_price:,} NESO")
                        invalid_items += 1
                        
                except (ValueError, TypeError) as e:
                    logger.debug(f"ä¾¡æ ¼å¤‰æ›ã‚¨ãƒ©ãƒ¼ ({item_id}): {price_str} -> {e}")
                    invalid_items += 1
                    continue
        except Exception as e:
            logger.error(f"ç·ä¾¡æ ¼è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
        
        logger.info(f"ç·ä¾¡æ ¼è¨ˆç®—çµæœ: {total_price:,} NESO ({valid_items}æœ‰åŠ¹ã‚¢ã‚¤ãƒ†ãƒ , {invalid_items}ç„¡åŠ¹ã‚¢ã‚¤ãƒ†ãƒ )")
        return total_price, valid_items

    def update_total_price_history(self, total_price, valid_items):
        """ç·ä¾¡æ ¼å±¥æ­´ã‚’æ›´æ–°"""
        if total_price == 0 or valid_items == 0:
            logger.warn("æœ‰åŠ¹ãªä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ã€ç·ä¾¡æ ¼å±¥æ­´ã‚’æ›´æ–°ã—ã¾ã›ã‚“")
            return []
        
        timestamp = datetime.now().isoformat()
        total_price_point = {
            'timestamp': timestamp,
            'total_price': total_price,
            'item_count': valid_items,
            'average_price': total_price // valid_items if valid_items > 0 else 0
        }
        
        # å„é–“éš”ã§ã®æ›´æ–°åˆ¤å®šã¨è¿½åŠ 
        updated_intervals = []
        for interval_type, config in self.price_intervals.items():
            if self.should_update_total_price_interval(interval_type):
                if interval_type not in self.total_price_history:
                    self.total_price_history[interval_type] = deque(maxlen=config['maxlen'])
                
                self.total_price_history[interval_type].append(total_price_point)
                updated_intervals.append(interval_type)
        
        if updated_intervals:
            logger.info(f"ç·ä¾¡æ ¼å±¥æ­´æ›´æ–°: {total_price:,} NESO ({valid_items}ã‚¢ã‚¤ãƒ†ãƒ ) - {updated_intervals}")
        
        return updated_intervals

    def save_total_price_history_to_files(self):
        """ç·ä¾¡æ ¼å±¥æ­´ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        try:
            for interval_type in self.price_intervals:
                total_file = os.path.join(self.history_dir, f"total_price_{interval_type}.json")
                if interval_type in self.total_price_history:
                    total_data = list(self.total_price_history[interval_type])
                    valid_total_data = []
                    for point in total_data:
                        if isinstance(point, dict) and 'timestamp' in point and 'total_price' in point:
                            valid_total_data.append(point)
                    
                    with open(total_file, 'w', encoding='utf-8') as f:
                        json.dump(valid_total_data, f, ensure_ascii=False, indent=2)
                    
                    logger.info(f"ç·ä¾¡æ ¼å±¥æ­´ä¿å­˜ {interval_type}: {len(valid_total_data)}ãƒã‚¤ãƒ³ãƒˆ")
        except Exception as e:
            logger.error(f"ç·ä¾¡æ ¼å±¥æ­´ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    def load_existing_chart_data(self, interval):
        """æ—¢å­˜ã®ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆä¿®æ­£ç‰ˆï¼šãƒ‡ãƒ¼ã‚¿è“„ç©å¯¾å¿œï¼‰"""
        chart_file = os.path.join(self.history_dir, f"total_price_{interval}.json")
        
        if not os.path.exists(chart_file):
            logger.info(f"ãƒãƒ£ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {chart_file}")
            return None
        
        try:
            with open(chart_file, 'r', encoding='utf-8') as f:
                existing_chart_data = json.load(f)
            
            # ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ç¢ºèª
            if (isinstance(existing_chart_data, dict) and 
                'labels' in existing_chart_data and 
                'datasets' in existing_chart_data):
                logger.info(f"æ—¢å­˜ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ {interval}: {len(existing_chart_data['labels'])}ãƒã‚¤ãƒ³ãƒˆ")
                return existing_chart_data
            else:
                logger.warn(f"æ—¢å­˜ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ãŒä¸æ­£: {interval}")
                return None
                
        except json.JSONDecodeError as e:
            logger.error(f"ãƒãƒ£ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {interval}: {e}")
            return None
        except Exception as e:
            logger.error(f"ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {interval}: {e}")
            return None

    def append_new_data_to_chart(self, existing_chart_data, new_data_point, interval):
        """æ—¢å­˜ã®ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã«æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’è¿½åŠ ï¼ˆä¿®æ­£ç‰ˆï¼šãƒ‡ãƒ¼ã‚¿è“„ç©å¯¾å¿œï¼‰"""
        try:
            # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’è§£æ
            timestamp = new_data_point['timestamp']
            total_price = new_data_point['total_price']
            average_price = new_data_point['average_price']
            
            # æ™‚åˆ»ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            def format_time(timestamp_str):
                try:
                    timestamp_obj = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
                    if interval == '1hour':
                        return timestamp_obj.strftime('%m/%d %H:%M')
                    elif interval == '12hour':
                        return timestamp_obj.strftime('%m/%d %H:%M')
                    else:  # 1day
                        return timestamp_obj.strftime('%m/%d')
                except Exception as e:
                    logger.error(f"æ™‚åˆ»ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {timestamp_str} -> {e}")
                    return timestamp_str
            
            formatted_time = format_time(timestamp)
            
            # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
            existing_chart_data['labels'].append(formatted_time)
            existing_chart_data['datasets'][0]['data'].append(total_price)  # ç·ä¾¡æ ¼
            existing_chart_data['datasets'][1]['data'].append(average_price)  # å¹³å‡ä¾¡æ ¼
            
            # maxlenã«åŸºã¥ã„ã¦å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
            max_points = self.price_intervals[interval]['maxlen']
            
            if len(existing_chart_data['labels']) > max_points:
                # å¤ã„ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å‰Šé™¤
                remove_count = len(existing_chart_data['labels']) - max_points
                existing_chart_data['labels'] = existing_chart_data['labels'][remove_count:]
                existing_chart_data['datasets'][0]['data'] = existing_chart_data['datasets'][0]['data'][remove_count:]
                existing_chart_data['datasets'][1]['data'] = existing_chart_data['datasets'][1]['data'][remove_count:]
            
            logger.info(f"ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿è¿½åŠ å®Œäº† {interval}: {len(existing_chart_data['labels'])}ãƒã‚¤ãƒ³ãƒˆ")
            return existing_chart_data
            
        except Exception as e:
            logger.error(f"ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿è¿½åŠ ã‚¨ãƒ©ãƒ¼ {interval}: {e}")
            return existing_chart_data

    def generate_total_price_chart_data(self, interval='1hour'):
        """ç·ä¾¡æ ¼ãƒãƒ£ãƒ¼ãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
        if interval not in self.total_price_history:
            logger.warn(f"ç·ä¾¡æ ¼å±¥æ­´ã«{interval}ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            return None
        
        history = list(self.total_price_history[interval])
        if not history:
            logger.warn(f"ç·ä¾¡æ ¼å±¥æ­´{interval}ãŒç©ºã§ã™")
            return None
        
        valid_points = []
        for point in history:
            if isinstance(point, dict) and 'timestamp' in point and 'total_price' in point and 'average_price' in point:
                total_price = point['total_price']
                avg_price = point['average_price']
                
                if total_price > 0 and avg_price > 0:
                    valid_points.append(point)
            else:
                logger.warn(f"ç·ä¾¡æ ¼å±¥æ­´ãƒ‡ãƒ¼ã‚¿æ§‹é€ ä¸æ­£: {point}")
        
        if len(valid_points) < 1:
            logger.error(f"æœ‰åŠ¹ãªç·ä¾¡æ ¼å±¥æ­´ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ ({interval}): {len(valid_points)}ãƒã‚¤ãƒ³ãƒˆ")
            return None
        
        def format_time(timestamp_str):
            try:
                timestamp = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
                if interval == '1hour':
                    return timestamp.strftime('%m/%d %H:%M')
                elif interval == '12hour':
                    return timestamp.strftime('%m/%d %H:%M')
                else:  # 1day
                    return timestamp.strftime('%m/%d')
            except Exception as e:
                logger.error(f"æ™‚åˆ»ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {timestamp_str} -> {e}")
                return timestamp_str
        
        try:
            chart_data = {
                'labels': [format_time(point['timestamp']) for point in valid_points],
                'datasets': [
                    {
                        'label': f'ç·ä¾¡æ ¼ ({self.price_intervals[interval]["description"]})',
                        'data': [point['total_price'] for point in valid_points],
                        'borderColor': '#e74c3c',
                        'backgroundColor': 'rgba(231, 76, 60, 0.1)',
                        'borderWidth': 3,
                        'fill': True,
                        'tension': 0.3,
                        'yAxisID': 'y'
                    },
                    {
                        'label': f'å¹³å‡ä¾¡æ ¼ ({self.price_intervals[interval]["description"]})',
                        'data': [point['average_price'] for point in valid_points],
                        'borderColor': '#3498db',
                        'backgroundColor': 'rgba(52, 152, 219, 0.1)',
                        'borderWidth': 2,
                        'fill': False,
                        'tension': 0.3,
                        'yAxisID': 'y1'
                    }
                ]
            }
            logger.info(f"ç·ä¾¡æ ¼ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº† {interval}: {len(valid_points)}ãƒã‚¤ãƒ³ãƒˆ")
            return chart_data
        except Exception as e:
            logger.error(f"ç·ä¾¡æ ¼ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def export_total_price_chart_data_for_web(self, interval='1hour'):
        """ç·ä¾¡æ ¼ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’Webç”¨ã«å‡ºåŠ›ï¼ˆä¿®æ­£ç‰ˆï¼šãƒ‡ãƒ¼ã‚¿è“„ç©å¯¾å¿œï¼‰"""
        try:
            # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’å–å¾—
            if interval not in self.total_price_history or not self.total_price_history[interval]:
                logger.warn(f"ç·ä¾¡æ ¼å±¥æ­´ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ ({interval})")
                return False
            
            # æœ€æ–°ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ
            latest_data_point = self.total_price_history[interval][-1]
            
            # æ—¢å­˜ã®ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
            existing_chart_data = self.load_existing_chart_data(interval)
            
            if existing_chart_data:
                # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã«æ–°ã—ã„ãƒã‚¤ãƒ³ãƒˆã‚’è¿½åŠ 
                updated_chart_data = self.append_new_data_to_chart(
                    existing_chart_data, 
                    latest_data_point, 
                    interval
                )
            else:
                # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯æ–°è¦ä½œæˆ
                logger.info(f"æ–°è¦ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ: {interval}")
                updated_chart_data = self.generate_total_price_chart_data(interval)
            
            if not updated_chart_data:
                logger.warn(f"ç·ä¾¡æ ¼ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ãŒç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸ ({interval})")
                return False
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            chart_file = os.path.join(self.history_dir, f"total_price_{interval}.json")
            with open(chart_file, 'w', encoding='utf-8') as f:
                json.dump(updated_chart_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ç·ä¾¡æ ¼ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿å‡ºåŠ›å®Œäº†: {chart_file} ({len(updated_chart_data['labels'])}ãƒã‚¤ãƒ³ãƒˆ)")
            return True
            
        except Exception as e:
            logger.error(f"ç·ä¾¡æ ¼ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿å‡ºåŠ›ã‚¨ãƒ©ãƒ¼ ({interval}): {e}")
            return False

    def process_total_price_aggregation(self):
        """ç·ä¾¡æ ¼é›†è¨ˆå‡¦ç†ã‚’å®Ÿè¡Œ"""
        try:
            # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç·ä¾¡æ ¼ã‚’è¨ˆç®—
            total_price, valid_items = self.calculate_total_price_from_json()
            
            # ç·ä¾¡æ ¼å±¥æ­´ã‚’æ›´æ–°
            total_intervals = self.update_total_price_history(total_price, valid_items)
            
            if total_intervals:
                # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                self.save_total_price_history_to_files()
                
                # Webç”¨ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿å‡ºåŠ›ï¼ˆãƒ‡ãƒ¼ã‚¿è“„ç©å¯¾å¿œï¼‰
                for interval in ['1hour', '12hour', '1day']:
                    try:
                        success = self.export_total_price_chart_data_for_web(interval)
                        if success:
                            logger.info(f"ç·ä¾¡æ ¼ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿å‡ºåŠ›æˆåŠŸ: {interval}")
                        else:
                            logger.warn(f"ç·ä¾¡æ ¼ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿å‡ºåŠ›å¤±æ•—: {interval}")
                    except Exception as e:
                        logger.error(f"ç·ä¾¡æ ¼ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿å‡ºåŠ›ã‚¨ãƒ©ãƒ¼ ({interval}): {e}")
                
                logger.info(f"ç·ä¾¡æ ¼é›†è¨ˆå‡¦ç†å®Œäº†: {total_price:,} NESO ({valid_items}ã‚¢ã‚¤ãƒ†ãƒ )")
            else:
                logger.info("ç·ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°ã¯ä¸è¦ã§ã—ãŸ")
            
            return len(total_intervals)
            
        except Exception as e:
            logger.error(f"ç·ä¾¡æ ¼é›†è¨ˆå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return 0

    def get_statistics(self):
        """ç·ä¾¡æ ¼å±¥æ­´çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        stats = {
            'total_price_intervals': {}
        }
        
        for interval_type, config in self.price_intervals.items():
            if interval_type in self.total_price_history:
                total_price_points = len(self.total_price_history[interval_type])
                stats['total_price_intervals'][interval_type] = {
                    'total_price_points': total_price_points,
                    'description': config['description']
                }
            else:
                stats['total_price_intervals'][interval_type] = {
                    'total_price_points': 0,
                    'description': config['description']
                }
        
        return stats

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œï¼šç·ä¾¡æ ¼é›†è¨ˆå‡¦ç†ï¼ˆãƒ‡ãƒ¼ã‚¿è“„ç©å¯¾å¿œï¼‰"""
    logger.info("=" * 50)
    logger.info("MapleStoryç·ä¾¡æ ¼é›†è¨ˆå‡¦ç†é–‹å§‹ï¼ˆãƒ‡ãƒ¼ã‚¿è“„ç©å¯¾å¿œï¼‰")
    logger.info("=" * 50)
    
    try:
        # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        logger.info("ç·ä¾¡æ ¼é›†è¨ˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–: data/price_history")
        aggregator = TotalPriceAggregator()
        
        # ç·ä¾¡æ ¼é›†è¨ˆå‡¦ç†å®Ÿè¡Œ
        updated = aggregator.process_total_price_aggregation()
        
        # çµ±è¨ˆè¡¨ç¤º
        stats = aggregator.get_statistics()
        logger.info(f"ğŸ“ˆ ç·ä¾¡æ ¼å±¥æ­´çµ±è¨ˆ:")
        for interval, data in stats['total_price_intervals'].items():
            logger.info(f"  {interval}: {data['total_price_points']}ãƒã‚¤ãƒ³ãƒˆ ({data['description']})")
        
        logger.info("=" * 50)
        logger.info(f"âœ… ç·ä¾¡æ ¼é›†è¨ˆå®Œäº†: {updated}é–“éš”æ›´æ–°ï¼ˆãƒ‡ãƒ¼ã‚¿è“„ç©å¯¾å¿œï¼‰")
        logger.info("=" * 50)
        
        return updated
        
    except Exception as e:
        logger.error(f"ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        raise

if __name__ == "__main__":
    main()
