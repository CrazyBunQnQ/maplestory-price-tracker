#!/usr/bin/env python3
import json
import os
from datetime import datetime, timedelta
from collections import defaultdict
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class TimestampTotalAggregator:
    def __init__(self, history_dir="data/price_history"):
        self.history_dir = history_dir
        self.intervals = ['1hour', '12hour', '1day']
        
        # è¡¨ç¤ºæœ€é©åŒ–è¨­å®š
        self.display_limits = {
            '1hour': 48,     # 48ãƒã‚¤ãƒ³ãƒˆï¼ˆ2æ—¥åˆ†ã€1æ™‚é–“æ¯ï¼‰
            '12hour': 60,    # 60ãƒã‚¤ãƒ³ãƒˆï¼ˆ1ãƒ¶æœˆåˆ†ã€12æ™‚é–“æ¯ï¼‰
            '1day': 30       # 30ãƒã‚¤ãƒ³ãƒˆï¼ˆ1ãƒ¶æœˆåˆ†ã€1æ—¥æ¯ï¼‰
        }
        
        # æ™‚é–“åŒºåˆ‡ã‚Šè¨­å®šï¼ˆè¡¨ç¤ºæœ€é©åŒ–ï¼‰
        self.bucket_intervals = {
            '1hour': timedelta(hours=1),      # 1æ™‚é–“åŒºåˆ‡ã‚Š
            '12hour': timedelta(hours=12),    # 12æ™‚é–“åŒºåˆ‡ã‚Š
            '1day': timedelta(days=1)         # 1æ—¥åŒºåˆ‡ã‚Š
        }
        
    def safe_parse_price(self, price_value):
        """ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’å®‰å…¨ã«è§£æ"""
        try:
            if isinstance(price_value, (int, float)):
                return int(price_value) if price_value > 0 else 0
            
            if isinstance(price_value, str):
                clean_price = price_value.replace(',', '').replace(' NESO', '').strip()
                if clean_price in ['', 'æœªå–å¾—', 'undefined', 'None', 'null']:
                    return 0
                return int(float(clean_price)) if float(clean_price) > 0 else 0
            
            return 0
            
        except (ValueError, TypeError, AttributeError):
            return 0
    
    def round_to_bucket(self, timestamp_str, interval):
        """é–“éš”ã«å¿œã˜ãŸæ™‚é–“åŒºåˆ‡ã‚Šã«ä¸¸ã‚ã‚‹ï¼ˆè¡¨ç¤ºæœ€é©åŒ–ï¼‰"""
        try:
            ts = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
            bucket_interval = self.bucket_intervals[interval]
            
            if interval == '1hour':
                # 1æ™‚é–“åŒºåˆ‡ã‚Š
                bucket_start = ts.replace(minute=0, second=0, microsecond=0)
            elif interval == '12hour':
                # 12æ™‚é–“åŒºåˆ‡ã‚Šï¼ˆ0æ™‚ã¾ãŸã¯12æ™‚ï¼‰
                hour_bucket = (ts.hour // 12) * 12
                bucket_start = ts.replace(hour=hour_bucket, minute=0, second=0, microsecond=0)
            else:  # '1day'
                # 1æ—¥åŒºåˆ‡ã‚Šï¼ˆ0æ™‚ï¼‰
                bucket_start = ts.replace(hour=0, minute=0, second=0, microsecond=0)
            
            return bucket_start.isoformat()
        except Exception as e:
            logger.warn(f"æ™‚é–“ä¸¸ã‚ã‚¨ãƒ©ãƒ¼: {timestamp_str} -> {e}")
            return timestamp_str
    
    def aggregate_prices_per_bucket(self, item_data_points, interval):
        """æ™‚é–“åŒºåˆ‡ã‚Šã«å¿œã˜ã¦ä¾¡æ ¼ã‚’å¹³å‡åŒ–ï¼ˆè¡¨ç¤ºæœ€é©åŒ–ï¼‰"""
        # æ™‚é–“åŒºåˆ‡ã‚Šã«ãƒ‡ãƒ¼ã‚¿ã‚’é›†ç´„
        bucketed = defaultdict(list)
        
        for point in item_data_points:
            if not isinstance(point, dict) or 'timestamp' not in point or 'price' not in point:
                continue
            
            bucket_time = self.round_to_bucket(point['timestamp'], interval)
            price = self.safe_parse_price(point['price'])
            
            if price > 0:
                bucketed[bucket_time].append(price)
        
        # å„æ™‚é–“åŒºåˆ‡ã‚Šã®å¹³å‡ä¾¡æ ¼ã‚’è¨ˆç®—
        averaged_data = []
        for bucket_time in sorted(bucketed.keys()):
            prices = bucketed[bucket_time]
            if prices:
                avg_price = sum(prices) // len(prices)  # æ•´æ•°å¹³å‡
                averaged_data.append({
                    'timestamp': bucket_time,
                    'price': avg_price,
                    'original_count': len(prices)
                })
        
        return averaged_data
    
    def limit_data_points(self, data_points, interval):
        """è¡¨ç¤ºæœ€é©åŒ–ã®ãŸã‚ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’åˆ¶é™"""
        limit = self.display_limits[interval]
        
        if len(data_points) <= limit:
            return data_points
        
        # æœ€æ–°ã®Nå€‹ã‚’å–å¾—
        limited_data = data_points[-limit:]
        logger.info(f"ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆåˆ¶é™ {interval}: {len(data_points)} -> {len(limited_data)}ãƒã‚¤ãƒ³ãƒˆ")
        
        return limited_data
    
    def aggregate_by_timestamp(self, interval):
        """æŒ‡å®šé–“éš”ã®å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’æ™‚é–“åŒºåˆ‡ã‚Šã§é›†è¨ˆï¼ˆè¡¨ç¤ºæœ€é©åŒ–ï¼‰"""
        history_file = os.path.join(self.history_dir, f"history_{interval}.json")
        
        if not os.path.exists(history_file):
            logger.warn(f"å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {history_file}")
            return []
        
        try:
            with open(history_file, 'r', encoding='utf-8') as f:
                all_items_data = json.load(f)
            
            if not isinstance(all_items_data, dict):
                logger.error(f"å±¥æ­´ãƒ‡ãƒ¼ã‚¿ãŒè¾æ›¸å‹ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {type(all_items_data)}")
                return []
            
            # æ™‚é–“åŒºåˆ‡ã‚Šã®æ™‚é–“æ åˆ¥ã«ç·ä¾¡æ ¼ã‚’é›†è¨ˆ
            timestamp_totals = defaultdict(lambda: {'total_price': 0, 'item_count': 0, 'total_points': 0})
            
            processed_items = 0
            total_averaged_points = 0
            
            for item_id, item_history in all_items_data.items():
                if not isinstance(item_history, list):
                    continue
                
                processed_items += 1
                
                # ã‚¢ã‚¤ãƒ†ãƒ æ¯ã«æ™‚é–“åŒºåˆ‡ã‚Šã§å¹³å‡åŒ–
                averaged_points = self.aggregate_prices_per_bucket(item_history, interval)
                total_averaged_points += len(averaged_points)
                
                # å¹³å‡åŒ–ã•ã‚ŒãŸãƒã‚¤ãƒ³ãƒˆã‚’æ™‚é–“è»¸ã§åˆè¨ˆ
                for avg_point in averaged_points:
                    bucket_time = avg_point['timestamp']
                    avg_price = avg_point['price']
                    original_count = avg_point['original_count']
                    
                    timestamp_totals[bucket_time]['total_price'] += avg_price
                    timestamp_totals[bucket_time]['item_count'] += 1
                    timestamp_totals[bucket_time]['total_points'] += original_count
            
            # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
            total_price_history = []
            for bucket_time in sorted(timestamp_totals.keys()):
                data = timestamp_totals[bucket_time]
                
                if data['item_count'] > 0:
                    total_price_history.append({
                        'timestamp': bucket_time,
                        'total_price': data['total_price'],
                        'item_count': data['item_count'],
                        'average_price': data['total_price'] // data['item_count'],
                        'original_points': data['total_points']
                    })
            
            # è¡¨ç¤ºæœ€é©åŒ–ã®ãŸã‚ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’åˆ¶é™
            limited_history = self.limit_data_points(total_price_history, interval)
            
            logger.info(f"æ™‚é–“åŒºåˆ‡ã‚Šé›†è¨ˆå®Œäº† {interval}: {len(limited_history)}æ™‚é–“æ ï¼ˆè¡¨ç¤ºæœ€é©åŒ–æ¸ˆã¿ï¼‰")
            logger.info(f"  å‡¦ç†ã‚¢ã‚¤ãƒ†ãƒ : {processed_items}, åŒºåˆ‡ã‚Šé–“éš”: {self.bucket_intervals[interval]}")
            
            return limited_history
            
        except json.JSONDecodeError as e:
            logger.error(f"JSONèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {interval}: {e}")
            return []
        except Exception as e:
            logger.error(f"é›†è¨ˆã‚¨ãƒ©ãƒ¼ {interval}: {e}")
            return []
    
    def generate_chart_data(self, interval, total_data):
        """Chart.jsç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆï¼ˆè¡¨ç¤ºæœ€é©åŒ–å¯¾å¿œï¼‰"""
        if not total_data:
            logger.error(f"ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ãªã—: {interval}")
            return None
        
        try:
            def format_time(timestamp_str):
                try:
                    timestamp = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
                    if interval == '1hour':
                        return timestamp.strftime('%m/%d %H:00')
                    elif interval == '12hour':
                        return timestamp.strftime('%m/%d %H:00')
                    else:  # 1day
                        return timestamp.strftime('%m/%d')
                except Exception as e:
                    logger.warn(f"æ™‚åˆ»ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {timestamp_str} -> {e}")
                    return str(timestamp_str)
            
            # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
            valid_points = []
            for point in total_data:
                if (isinstance(point, dict) and 
                    'timestamp' in point and 
                    'total_price' in point and 
                    'average_price' in point and
                    isinstance(point['total_price'], int) and
                    isinstance(point['average_price'], int) and
                    point['total_price'] > 0):
                    valid_points.append(point)
            
            if len(valid_points) == 0:
                logger.error(f"æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“: {interval}")
                return None
            
            labels = [format_time(point['timestamp']) for point in valid_points]
            total_prices = [point['total_price'] for point in valid_points]
            average_prices = [point['average_price'] for point in valid_points]
            
            chart_data = {
                'labels': labels,
                'datasets': [
                    {
                        'label': f'ç·ä¾¡æ ¼ ({interval})',
                        'data': total_prices,
                        'borderColor': '#e74c3c',
                        'backgroundColor': 'rgba(231, 76, 60, 0.1)',
                        'borderWidth': 2,
                        'fill': True,
                        'tension': 0.4,
                        'pointRadius': 2,
                        'pointHoverRadius': 4,
                        'yAxisID': 'y'
                    },
                    {
                        'label': f'å¹³å‡ä¾¡æ ¼ ({interval})',
                        'data': average_prices,
                        'borderColor': '#3498db',
                        'backgroundColor': 'rgba(52, 152, 219, 0.1)',
                        'borderWidth': 2,
                        'fill': False,
                        'tension': 0.4,
                        'pointRadius': 1,
                        'pointHoverRadius': 3,
                        'yAxisID': 'y1'
                    }
                ]
            }
            
            logger.info(f"è¡¨ç¤ºæœ€é©åŒ–ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº† {interval}: {len(valid_points)}ãƒã‚¤ãƒ³ãƒˆ")
            logger.info(f"  æ™‚é–“ç¯„å›²: {labels[0]} ï½ {labels[-1]}")
            
            return chart_data
            
        except Exception as e:
            logger.error(f"ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼ {interval}: {e}")
            return None
    
    def save_total_data(self, interval, total_data):
        """ç·ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ï¼ˆè¡¨ç¤ºæœ€é©åŒ–å¯¾å¿œï¼‰"""
        if not total_data:
            logger.warn(f"ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“: {interval}")
            return False
        
        try:
            # ç”Ÿãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä¿å­˜
            raw_file = os.path.join(self.history_dir, f"total_price_optimized_{interval}.json")
            with open(raw_file, 'w', encoding='utf-8') as f:
                json.dump(total_data, f, ensure_ascii=False, indent=2)
            
            # Chart.jsç”¨ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä¿å­˜
            chart_data = self.generate_chart_data(interval, total_data)
            if chart_data:
                chart_file = os.path.join(self.history_dir, f"total_price_{interval}.json")
                with open(chart_file, 'w', encoding='utf-8') as f:
                    json.dump(chart_data, f, ensure_ascii=False, indent=2)
                
                logger.info(f"è¡¨ç¤ºæœ€é©åŒ–ä¿å­˜å®Œäº† {interval}: {len(total_data)}æ™‚é–“æ  -> {len(chart_data['labels'])}ãƒãƒ£ãƒ¼ãƒˆãƒã‚¤ãƒ³ãƒˆ")
            else:
                logger.error(f"ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå¤±æ•—: {interval}")
                return False
                
            return True
            
        except Exception as e:
            logger.error(f"ä¿å­˜ã‚¨ãƒ©ãƒ¼ {interval}: {e}")
            return False
    
    def process_all(self):
        """å…¨é–“éš”ã®å‡¦ç†ã‚’å®Ÿè¡Œï¼ˆè¡¨ç¤ºæœ€é©åŒ–å¯¾å¿œï¼‰"""
        results = {}
        
        for interval in self.intervals:
            logger.info(f"è¡¨ç¤ºæœ€é©åŒ–å‡¦ç†é–‹å§‹: {interval}")
            
            # æ™‚é–“åŒºåˆ‡ã‚Šã§é›†è¨ˆï¼ˆè¡¨ç¤ºæœ€é©åŒ–ï¼‰
            total_data = self.aggregate_by_timestamp(interval)
            
            if total_data:
                # ä¿å­˜
                saved = self.save_total_data(interval, total_data)
                
                results[interval] = {
                    'total_buckets': len(total_data),
                    'saved': saved,
                    'latest_total': total_data[-1]['total_price'] if total_data else 0,
                    'latest_count': total_data[-1]['item_count'] if total_data else 0,
                    'bucket_interval': str(self.bucket_intervals[interval]),
                    'display_limit': self.display_limits[interval]
                }
                
                # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯
                if total_data:
                    prices = [p['total_price'] for p in total_data]
                    logger.info(f"  ä¾¡æ ¼ç¯„å›²: {min(prices):,} - {max(prices):,} NESO")
            else:
                results[interval] = {
                    'total_buckets': 0,
                    'saved': False,
                    'latest_total': 0,
                    'latest_count': 0,
                    'bucket_interval': str(self.bucket_intervals[interval]),
                    'display_limit': self.display_limits[interval]
                }
        
        return results

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œï¼šè¡¨ç¤ºæœ€é©åŒ–ç·ä¾¡æ ¼é›†è¨ˆ"""
    logger.info("=" * 50)
    logger.info("MapleStoryç·ä¾¡æ ¼é›†è¨ˆï¼ˆè¡¨ç¤ºæœ€é©åŒ–ç‰ˆï¼‰é–‹å§‹")
    logger.info("=" * 50)
    
    try:
        aggregator = TimestampTotalAggregator()
        
        # é›†è¨ˆå‡¦ç†å®Ÿè¡Œ
        results = aggregator.process_all()
        
        # çµæœè¡¨ç¤º
        logger.info("ğŸ“Š è¡¨ç¤ºæœ€é©åŒ–é›†è¨ˆçµæœ:")
        for interval, result in results.items():
            logger.info(f"  {interval}: {result['total_buckets']}æ™‚é–“æ ")
            logger.info(f"    åŒºåˆ‡ã‚Šé–“éš”: {result['bucket_interval']}")
            logger.info(f"    è¡¨ç¤ºåˆ¶é™: {result['display_limit']}ãƒã‚¤ãƒ³ãƒˆ")
            if result['latest_total'] > 0:
                logger.info(f"    æœ€æ–°ç·ä¾¡æ ¼: {result['latest_total']:,} NESO ({result['latest_count']}ã‚¢ã‚¤ãƒ†ãƒ )")
        
        successful = sum(1 for r in results.values() if r['saved'])
        logger.info(f"âœ… è¡¨ç¤ºæœ€é©åŒ–å‡¦ç†å®Œäº†: {successful}/{len(aggregator.intervals)}é–“éš”æˆåŠŸ")
        
        return successful
        
    except Exception as e:
        logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return 0

if __name__ == "__main__":
    main()
