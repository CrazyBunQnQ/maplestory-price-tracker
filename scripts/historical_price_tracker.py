#!/usr/bin/env python3
import json
import time
import os
from datetime import datetime, timedelta
from collections import deque, defaultdict
import logging
import statistics

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class HistoricalPriceTracker:
    def __init__(self, json_file_path="data/equipment_prices.json", 
                 history_dir="data/price_history"):
        self.json_file_path = json_file_path
        self.history_dir = history_dir
        
        # ç·©å’Œç‰ˆè¨­å®š: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§å¼·åˆ¶æ¤œå‡ºã‚’æœ‰åŠ¹åŒ–
        self.force_price_detection = os.getenv('FORCE_PRICE_DETECTION', 'true').lower() == 'true'
        self.force_rebuild_history = os.getenv('FORCE_REBUILD_HISTORY', 'false').lower() == 'true'
        
        # ç·©å’Œç‰ˆè¨­å®š: ã‚ˆã‚Šç©æ¥µçš„ãªãƒ‡ãƒ¼ã‚¿è“„ç©
        self.relaxed_mode = os.getenv('RELAXED_MODE', 'true').lower() == 'true'
        self.time_threshold_ratio = float(os.getenv('TIME_THRESHOLD_RATIO', '0.9'))  # 70%çµŒéã§æ›´æ–°
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(history_dir, exist_ok=True)
        
        # ä¿®æ­£: 30åˆ†æ¯ãƒ‡ãƒ¼ã‚¿åé›†ã¨æ™‚é–“é–“éš”åˆ¥é›†ç´„è¨­å®š
        self.raw_data_interval = timedelta(minutes=30)  # 30åˆ†æ¯ã®ç”Ÿãƒ‡ãƒ¼ã‚¿
        
        # ãƒãƒ£ãƒ¼ãƒˆç”¨æ™‚é–“é–“éš”è¨­å®šï¼ˆ30åˆ†æ¯ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é›†ç´„ï¼‰
        self.price_intervals = {
            '1hour': {
                'interval': timedelta(hours=1),
                'maxlen': 168,  # 1é€±é–“åˆ†ï¼ˆ168æ™‚é–“ï¼‰
                'description': '1é€±é–“åˆ†ï¼ˆ1æ™‚é–“æ¯ï¼‰',
                'aggregation_points': 2  # 30åˆ†Ã—2 = 1æ™‚é–“
            },
            '12hour': {
                'interval': timedelta(hours=12),
                'maxlen': 60,   # 1ãƒ¶æœˆåˆ†ï¼ˆ60å› = 30æ—¥ï¼‰
                'description': '1ãƒ¶æœˆåˆ†ï¼ˆ12æ™‚é–“æ¯ï¼‰',
                'aggregation_points': 24  # 30åˆ†Ã—24 = 12æ™‚é–“
            },
            '1day': {
                'interval': timedelta(days=1),
                'maxlen': 365,  # 1å¹´åˆ†ï¼ˆ365æ—¥ï¼‰
                'description': '1å¹´åˆ†ï¼ˆ1æ—¥æ¯ï¼‰',
                'aggregation_points': 48  # 30åˆ†Ã—48 = 24æ™‚é–“
            }
        }
        
        # 30åˆ†æ¯ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ä¿å­˜ç”¨ï¼ˆå€‹åˆ¥ã‚¢ã‚¤ãƒ†ãƒ ï¼‰
        self.raw_price_data = {}
        
        # é›†ç´„ã•ã‚ŒãŸä¾¡æ ¼å±¥æ­´ï¼ˆå€‹åˆ¥ã‚¢ã‚¤ãƒ†ãƒ ï¼‰
        self.price_history = {}
        
        # ç·ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆ30åˆ†æ¯ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ï¼‰
        self.total_price_raw_data = deque(maxlen=2880)  # 30æ—¥åˆ†ã®30åˆ†æ¯ãƒ‡ãƒ¼ã‚¿
        
        # ç·ä¾¡æ ¼å±¥æ­´ï¼ˆé›†ç´„æ¸ˆã¿ï¼‰
        self.total_price_history = {}
        
        # ç¾åœ¨ã®ä¾¡æ ¼ã‚’è¨˜éŒ²ã™ã‚‹ãŸã‚ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self.current_prices = {}
        
        # ç·©å’Œç‰ˆ: æ›´æ–°çµ±è¨ˆ
        self.update_statistics = {
            'forced_updates': 0,
            'time_based_updates': 0,
            'price_change_updates': 0,
            'first_time_updates': 0
        }
        
        logger.info("ğŸ”§ ä¾¡æ ¼å±¥æ­´è¿½è·¡ã‚·ã‚¹ãƒ†ãƒ ï¼ˆ30åˆ†æ¯ãƒ‡ãƒ¼ã‚¿é›†ç´„ç‰ˆï¼‰åˆæœŸåŒ–")
        logger.info(f"ğŸ”„ å¼·åˆ¶ä¾¡æ ¼æ¤œå‡º: {'æœ‰åŠ¹' if self.force_price_detection else 'ç„¡åŠ¹'}")
        logger.info(f"âš¡ ç·©å’Œãƒ¢ãƒ¼ãƒ‰: {'æœ‰åŠ¹' if self.relaxed_mode else 'ç„¡åŠ¹'}")
        logger.info(f"â° æ™‚é–“é–¾å€¤: {self.time_threshold_ratio*100:.0f}%çµŒéã§æ›´æ–°")
        logger.info(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿åé›†é–“éš”: 30åˆ†æ¯")
        
        self.load_existing_history()

    def load_existing_history(self):
        """æ—¢å­˜ã®ä¾¡æ ¼å±¥æ­´ã‚’èª­ã¿è¾¼ã¿ï¼ˆ30åˆ†æ¯ãƒ‡ãƒ¼ã‚¿ã¨é›†ç´„ãƒ‡ãƒ¼ã‚¿ï¼‰"""
        try:
            # 30åˆ†æ¯ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
            self.load_raw_data()
            
            # é›†ç´„æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
            self.load_aggregated_data()
            
            # ç·ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
            self.load_total_price_data()
            
        except Exception as e:
            logger.error(f"ä¾¡æ ¼å±¥æ­´èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    def load_raw_data(self):
        """30åˆ†æ¯ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            raw_data_file = os.path.join(self.history_dir, "raw_price_data.json")
            if os.path.exists(raw_data_file):
                with open(raw_data_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                for item_id, raw_history in data.items():
                    self.raw_price_data[item_id] = deque(
                        raw_history, 
                        maxlen=2880  # 30æ—¥åˆ†ã®30åˆ†æ¯ãƒ‡ãƒ¼ã‚¿
                    )
                    
                logger.info(f"30åˆ†æ¯ç”Ÿãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(self.raw_price_data)}ã‚¢ã‚¤ãƒ†ãƒ ")
        except Exception as e:
            logger.warning(f"30åˆ†æ¯ç”Ÿãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    def load_aggregated_data(self):
        """é›†ç´„æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            total_records = 0
            
            for interval_type in self.price_intervals:
                history_file = os.path.join(self.history_dir, f"history_{interval_type}.json")
                if os.path.exists(history_file):
                    with open(history_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        item_count = len(data)
                        for item_id, history in data.items():
                            if item_id not in self.price_history:
                                self.price_history[item_id] = {}
                            
                            # dequeã«å¤‰æ›ã—ã¦æœ€å¤§é•·ã‚’é©ç”¨
                            self.price_history[item_id][interval_type] = deque(
                                history, 
                                maxlen=self.price_intervals[interval_type]['maxlen']
                            )
                            total_records += len(history)
                        
                        logger.info(f"{interval_type} é›†ç´„å±¥æ­´èª­ã¿è¾¼ã¿: {item_count}ã‚¢ã‚¤ãƒ†ãƒ ")
            
            logger.info(f"å€‹åˆ¥ã‚¢ã‚¤ãƒ†ãƒ é›†ç´„å±¥æ­´èª­ã¿è¾¼ã¿å®Œäº†: {len(self.price_history)}ã‚¢ã‚¤ãƒ†ãƒ ã€{total_records}ãƒ¬ã‚³ãƒ¼ãƒ‰")
            
        except Exception as e:
            logger.warning(f"é›†ç´„ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    def load_total_price_data(self):
        """ç·ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            # 30åˆ†æ¯ã®ç·ä¾¡æ ¼ç”Ÿãƒ‡ãƒ¼ã‚¿
            total_raw_file = os.path.join(self.history_dir, "total_price_raw_data.json")
            if os.path.exists(total_raw_file):
                with open(total_raw_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.total_price_raw_data = deque(data, maxlen=2880)
                    logger.info(f"ç·ä¾¡æ ¼30åˆ†æ¯ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(self.total_price_raw_data)}ãƒ¬ã‚³ãƒ¼ãƒ‰")
            
            # é›†ç´„æ¸ˆã¿ç·ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            for interval_type in self.price_intervals:
                total_file = os.path.join(self.history_dir, f"total_price_{interval_type}.json")
                if os.path.exists(total_file):
                    with open(total_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        if interval_type not in self.total_price_history:
                            self.total_price_history[interval_type] = data
                        logger.info(f"ç·ä¾¡æ ¼{interval_type}ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†")
                        
        except Exception as e:
            logger.warning(f"ç·ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    def save_history_to_files(self):
        """ä¾¡æ ¼å±¥æ­´ã‚’å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆ30åˆ†æ¯ç”Ÿãƒ‡ãƒ¼ã‚¿ + é›†ç´„ãƒ‡ãƒ¼ã‚¿ + ç·ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ï¼‰"""
        try:
            # 30åˆ†æ¯ç”Ÿãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
            self.save_raw_data()
            
            # é›†ç´„ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
            self.save_aggregated_data()
            
            # ç·ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
            self.save_total_price_data()
            
        except Exception as e:
            logger.error(f"ä¾¡æ ¼å±¥æ­´ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    def save_raw_data(self):
        """30åˆ†æ¯ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        try:
            raw_data_file = os.path.join(self.history_dir, "raw_price_data.json")
            raw_data = {}
            
            for item_id, raw_history in self.raw_price_data.items():
                if len(raw_history) > 0:
                    raw_data[item_id] = list(raw_history)
            
            with open(raw_data_file, 'w', encoding='utf-8') as f:
                json.dump(raw_data, f, ensure_ascii=False, indent=2)
                
            logger.info(f"30åˆ†æ¯ç”Ÿãƒ‡ãƒ¼ã‚¿ä¿å­˜: {len(raw_data)}ã‚¢ã‚¤ãƒ†ãƒ ")
        except Exception as e:
            logger.error(f"30åˆ†æ¯ç”Ÿãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    def save_aggregated_data(self):
        """é›†ç´„ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        try:
            for interval_type in self.price_intervals:
                history_file = os.path.join(self.history_dir, f"history_{interval_type}.json")
                
                # dequeã‚’ãƒªã‚¹ãƒˆã«å¤‰æ›ã—ã¦ä¿å­˜
                interval_data = {}
                total_points = 0
                
                for item_id, intervals in self.price_history.items():
                    if interval_type in intervals and len(intervals[interval_type]) > 0:
                        interval_data[item_id] = list(intervals[interval_type])
                        total_points += len(intervals[interval_type])
                
                with open(history_file, 'w', encoding='utf-8') as f:
                    json.dump(interval_data, f, ensure_ascii=False, indent=2)
                
                logger.info(f"{interval_type} é›†ç´„å±¥æ­´ä¿å­˜: {len(interval_data)}ã‚¢ã‚¤ãƒ†ãƒ ã€{total_points}ãƒã‚¤ãƒ³ãƒˆ")
        except Exception as e:
            logger.error(f"é›†ç´„ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    def save_total_price_data(self):
        """ç·ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        try:
            # 30åˆ†æ¯ã®ç·ä¾¡æ ¼ç”Ÿãƒ‡ãƒ¼ã‚¿
            total_raw_file = os.path.join(self.history_dir, "total_price_raw_data.json")
            with open(total_raw_file, 'w', encoding='utf-8') as f:
                json.dump(list(self.total_price_raw_data), f, ensure_ascii=False, indent=2)
            
            # é›†ç´„æ¸ˆã¿ç·ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            for interval_type in self.price_intervals:
                if interval_type in self.total_price_history:
                    total_file = os.path.join(self.history_dir, f"total_price_{interval_type}.json")
                    with open(total_file, 'w', encoding='utf-8') as f:
                        json.dump(self.total_price_history[interval_type], f, ensure_ascii=False, indent=2)
                    
            logger.info("ç·ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†")
        except Exception as e:
            logger.error(f"ç·ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    def add_raw_price_data(self, item_id, item_name, current_price):
        """30åˆ†æ¯ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ """
        timestamp = datetime.now().isoformat()
        price_point = {
            'timestamp': timestamp,
            'price': current_price,
            'item_name': item_name
        }
        
        if item_id not in self.raw_price_data:
            self.raw_price_data[item_id] = deque(maxlen=2880)
        
        self.raw_price_data[item_id].append(price_point)
        logger.debug(f"30åˆ†æ¯ãƒ‡ãƒ¼ã‚¿è¿½åŠ : {item_name} - {current_price:,}")

    def aggregate_price_data_for_interval(self, item_id, interval_type):
        """30åˆ†æ¯ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æŒ‡å®šé–“éš”ã§é›†ç´„"""
        if item_id not in self.raw_price_data:
            return []
        
        raw_data = list(self.raw_price_data[item_id])
        if not raw_data:
            return []
        
        config = self.price_intervals[interval_type]
        interval_duration = config['interval']
        
        aggregated_data = []
        current_group = []
        group_start_time = None
        
        for data_point in raw_data:
            try:
                point_time = datetime.fromisoformat(data_point['timestamp'].replace('Z', '+00:00'))
                
                if group_start_time is None:
                    group_start_time = point_time
                    current_group = [data_point]
                elif point_time - group_start_time < interval_duration:
                    current_group.append(data_point)
                else:
                    # ç¾åœ¨ã®ã‚°ãƒ«ãƒ¼ãƒ—ã‚’é›†ç´„
                    if current_group:
                        avg_price = statistics.mean([p['price'] for p in current_group])
                        aggregated_data.append({
                            'timestamp': current_group[-1]['timestamp'],  # æœ€æ–°ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ä½¿ç”¨
                            'price': int(avg_price),
                            'item_name': current_group[0]['item_name'],
                            'data_points': len(current_group)
                        })
                    
                    # æ–°ã—ã„ã‚°ãƒ«ãƒ¼ãƒ—ã‚’é–‹å§‹
                    group_start_time = point_time
                    current_group = [data_point]
                    
            except Exception as e:
                logger.debug(f"ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        # æœ€å¾Œã®ã‚°ãƒ«ãƒ¼ãƒ—ã‚’å‡¦ç†
        if current_group:
            avg_price = statistics.mean([p['price'] for p in current_group])
            aggregated_data.append({
                'timestamp': current_group[-1]['timestamp'],
                'price': int(avg_price),
                'item_name': current_group[0]['item_name'],
                'data_points': len(current_group)
            })
        
        return aggregated_data

    def update_total_price_data(self, all_current_prices):
        """ç·ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ï¼ˆ30åˆ†æ¯ + é›†ç´„ï¼‰"""
        timestamp = datetime.now().isoformat()
        
        # æœ‰åŠ¹ãªä¾¡æ ¼ã®ã¿ã‚’è¨ˆç®—
        valid_prices = [price for price in all_current_prices.values() if price > 0]
        
        if not valid_prices:
            logger.warning("æœ‰åŠ¹ãªä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        total_price = sum(valid_prices)
        average_price = int(statistics.mean(valid_prices))
        
        # 30åˆ†æ¯ã®ç·ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        total_point = {
            'timestamp': timestamp,
            'total_price': total_price,
            'average_price': average_price,
            'item_count': len(valid_prices)
        }
        
        self.total_price_raw_data.append(total_point)
        
        # å„é–“éš”ã§ã®é›†ç´„æ¸ˆã¿ç·ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
        for interval_type in self.price_intervals:
            self.aggregate_total_price_for_interval(interval_type)
        
        logger.info(f"ç·ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿æ›´æ–°: åˆè¨ˆ{total_price:,} NESO, å¹³å‡{average_price:,} NESO ({len(valid_prices)}ã‚¢ã‚¤ãƒ†ãƒ )")

    def aggregate_total_price_for_interval(self, interval_type):
        """ç·ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’æŒ‡å®šé–“éš”ã§é›†ç´„"""
        if not self.total_price_raw_data:
            return
        
        config = self.price_intervals[interval_type]
        interval_duration = config['interval']
        
        raw_data = list(self.total_price_raw_data)
        aggregated_data = []
        current_group = []
        group_start_time = None
        
        for data_point in raw_data:
            try:
                point_time = datetime.fromisoformat(data_point['timestamp'].replace('Z', '+00:00'))
                
                if group_start_time is None:
                    group_start_time = point_time
                    current_group = [data_point]
                elif point_time - group_start_time < interval_duration:
                    current_group.append(data_point)
                else:
                    # ç¾åœ¨ã®ã‚°ãƒ«ãƒ¼ãƒ—ã‚’é›†ç´„
                    if current_group:
                        avg_total = int(statistics.mean([p['total_price'] for p in current_group]))
                        avg_average = int(statistics.mean([p['average_price'] for p in current_group]))
                        avg_count = int(statistics.mean([p['item_count'] for p in current_group]))
                        
                        aggregated_data.append({
                            'timestamp': current_group[-1]['timestamp'],
                            'total_price': avg_total,
                            'average_price': avg_average,
                            'item_count': avg_count,
                            'data_points': len(current_group)
                        })
                    
                    # æ–°ã—ã„ã‚°ãƒ«ãƒ¼ãƒ—ã‚’é–‹å§‹
                    group_start_time = point_time
                    current_group = [data_point]
                    
            except Exception as e:
                logger.debug(f"ç·ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        # æœ€å¾Œã®ã‚°ãƒ«ãƒ¼ãƒ—ã‚’å‡¦ç†
        if current_group:
            avg_total = int(statistics.mean([p['total_price'] for p in current_group]))
            avg_average = int(statistics.mean([p['average_price'] for p in current_group]))
            avg_count = int(statistics.mean([p['item_count'] for p in current_group]))
            
            aggregated_data.append({
                'timestamp': current_group[-1]['timestamp'],
                'total_price': avg_total,
                'average_price': avg_average,
                'item_count': avg_count,
                'data_points': len(current_group)
            })
        
        # Chart.jsç”¨ã®ãƒ‡ãƒ¼ã‚¿å½¢å¼ã§ä¿å­˜
        chart_data = self.format_total_price_chart_data(aggregated_data, interval_type)
        self.total_price_history[interval_type] = chart_data

    def format_total_price_chart_data(self, aggregated_data, interval_type):
        """ç·ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’Chart.jså½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        if not aggregated_data:
            return {"labels": [], "datasets": []}
        
        # æ™‚åˆ»ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’é–“éš”ã«å¿œã˜ã¦èª¿æ•´
        def format_time(timestamp_str):
            try:
                timestamp = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
                if interval_type == '1hour':
                    return timestamp.strftime('%m/%d %H:%M')
                elif interval_type == '12hour':
                    return timestamp.strftime('%m/%d %H:%M')
                else:  # 1day
                    return timestamp.strftime('%m/%d')
            except:
                return timestamp_str
        
        labels = [format_time(point['timestamp']) for point in aggregated_data]
        total_prices = [point['total_price'] for point in aggregated_data]
        average_prices = [point['average_price'] for point in aggregated_data]
        
        config = self.price_intervals[interval_type]
        
        return {
            'labels': labels,
            'datasets': [
                {
                    'label': f'ç·ä¾¡æ ¼ ({config["description"]})',
                    'data': total_prices,
                    'borderColor': '#e74c3c',
                    'backgroundColor': 'rgba(231, 76, 60, 0.1)',
                    'borderWidth': 3,
                    'fill': True,
                    'tension': 0.3,
                    'yAxisID': 'y'
                },
                {
                    'label': f'å¹³å‡ä¾¡æ ¼ ({config["description"]})',
                    'data': average_prices,
                    'borderColor': '#3498db',
                    'backgroundColor': 'rgba(52, 152, 219, 0.1)',
                    'borderWidth': 2,
                    'fill': False,
                    'tension': 0.3,
                    'yAxisID': 'y1'
                }
            ]
        }

    def should_update_interval(self, item_id, interval_type, current_price):
        """ç·©å’Œç‰ˆ: ã‚ˆã‚Šç©æ¥µçš„ãªæ›´æ–°åˆ¤å®šï¼ˆ30åˆ†æ¯ãƒ‡ãƒ¼ã‚¿å¯¾å¿œï¼‰"""
        
        # å¼·åˆ¶æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯ç„¡æ¡ä»¶æ›´æ–°
        if self.force_price_detection:
            self.update_statistics['forced_updates'] += 1
            return True
        
        # 30åˆ†æ¯ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ã¯å¸¸ã«è¿½åŠ 
        return True

    def detect_price_changes_from_last_updated(self, item_data):
        """last_updatedãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ã‚ˆã‚‹æœ€è¿‘ã®æ›´æ–°æ¤œå‡ºï¼ˆç·©å’Œç‰ˆï¼‰"""
        try:
            last_updated = item_data.get('last_updated')
            if not last_updated:
                return False
            
            # last_updatedã®æ™‚åˆ»ã‚’ãƒ‘ãƒ¼ã‚¹
            update_time = datetime.fromisoformat(last_updated.replace('Z', '+00:00'))
            now = datetime.now()
            
            # ç·©å’Œç‰ˆ: 2æ™‚é–“ä»¥å†…ã®æ›´æ–°ã‚’æ¤œå‡ºï¼ˆå¾“æ¥ã¯1æ™‚é–“ï¼‰
            time_diff = (now - update_time).total_seconds()
            is_recent_update = time_diff < 7200  # 2æ™‚é–“
            
            if is_recent_update:
                logger.info(f"æœ€è¿‘ã®æ›´æ–°æ¤œå‡º: {item_data.get('item_name')} - {time_diff:.0f}ç§’å‰")
                return True
                
            return False
            
        except Exception as e:
            logger.debug(f"last_updatedè§£æã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def update_price_history(self, item_id, item_name, current_price):
        """ä¾¡æ ¼å±¥æ­´ã‚’æ›´æ–°ï¼ˆ30åˆ†æ¯ãƒ‡ãƒ¼ã‚¿ + é›†ç´„å‡¦ç†ï¼‰"""
        # 30åˆ†æ¯ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        self.add_raw_price_data(item_id, item_name, current_price)
        
        # ç¾åœ¨ä¾¡æ ¼ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
        self.current_prices[item_id] = current_price
        
        # å„é–“éš”ã§ã®é›†ç´„ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
        updated_intervals = []
        for interval_type in self.price_intervals:
            aggregated_data = self.aggregate_price_data_for_interval(item_id, interval_type)
            
            if aggregated_data:
                if item_id not in self.price_history:
                    self.price_history[item_id] = {}
                
                if interval_type not in self.price_history[item_id]:
                    config = self.price_intervals[interval_type]
                    self.price_history[item_id][interval_type] = deque(maxlen=config['maxlen'])
                
                # æœ€æ–°ã®é›†ç´„ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’è¿½åŠ ï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰
                latest_data = aggregated_data[-1]
                
                # é‡è¤‡ãƒã‚§ãƒƒã‚¯
                current_history = list(self.price_history[item_id][interval_type])
                if not current_history or current_history[-1]['timestamp'] != latest_data['timestamp']:
                    self.price_history[item_id][interval_type].append(latest_data)
                    updated_intervals.append(interval_type)
        
        if updated_intervals:
            logger.debug(f"{item_name} é›†ç´„å±¥æ­´æ›´æ–°: {updated_intervals}")
        
        return updated_intervals

    def update_from_current_prices(self):
        """ç¾åœ¨ã®ä¾¡æ ¼JSONã‹ã‚‰å±¥æ­´ã‚’æ›´æ–°ï¼ˆ30åˆ†æ¯ãƒ‡ãƒ¼ã‚¿å¯¾å¿œç‰ˆï¼‰"""
        try:
            if not os.path.exists(self.json_file_path):
                logger.error(f"ä¾¡æ ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.json_file_path}")
                return 0
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ€çµ‚æ›´æ–°æ™‚åˆ»ã‚’ãƒã‚§ãƒƒã‚¯
            file_mtime = os.path.getmtime(self.json_file_path)
            file_age = time.time() - file_mtime
            
            logger.info(f"ä¾¡æ ¼ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: {self.json_file_path} (æ›´æ–°ã‹ã‚‰{file_age:.0f}ç§’çµŒé)")
            
            with open(self.json_file_path, 'r', encoding='utf-8') as f:
                current_data = json.load(f)
            
            logger.info(f"ç¾åœ¨ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(current_data)}ã‚¢ã‚¤ãƒ†ãƒ ")
            
            # çµ±è¨ˆç”¨ã‚«ã‚¦ãƒ³ã‚¿ãƒªã‚»ãƒƒãƒˆ
            self.update_statistics = {k: 0 for k in self.update_statistics}
            
            updated_count = 0
            processed_count = 0
            force_updated_count = 0
            recent_update_count = 0
            all_current_prices = {}
            
            for item_id, item_data in current_data.items():
                processed_count += 1
                
                # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
                if not item_data or not isinstance(item_data, dict):
                    continue
                    
                if not item_data.get('item_name') or not item_data.get('item_price'):
                    continue
                
                # æœ€è¿‘ã®æ›´æ–°æ¤œå‡ºï¼ˆç·©å’Œç‰ˆï¼‰
                is_recent_update = self.detect_price_changes_from_last_updated(item_data)
                if is_recent_update:
                    recent_update_count += 1
                
                # ä¾¡æ ¼æ–‡å­—åˆ—ã‚’æ•°å€¤ã«å¤‰æ›
                price_str = str(item_data['item_price']).replace(',', '').replace(' NESO', '').strip()
                try:
                    current_price = int(price_str)
                    if current_price > 0:
                        all_current_prices[item_id] = current_price
                        
                        # 30åˆ†æ¯ã®ãƒ‡ãƒ¼ã‚¿æ›´æ–°ï¼ˆå¸¸ã«å®Ÿè¡Œï¼‰
                        intervals = self.update_price_history(
                            item_id, 
                            item_data['item_name'], 
                            current_price
                        )
                        
                        if intervals or self.force_price_detection:
                            updated_count += 1
                            if self.force_price_detection:
                                force_updated_count += 1
                            
                except (ValueError, TypeError) as e:
                    logger.debug(f"ä¾¡æ ¼å¤‰æ›ã‚¨ãƒ©ãƒ¼ ({item_id}): {price_str} -> {e}")
                    continue
            
            # ç·ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
            if all_current_prices:
                self.update_total_price_data(all_current_prices)
            
            logger.info(f"30åˆ†æ¯ãƒ‡ãƒ¼ã‚¿å‡¦ç†å®Œäº†: å‡¦ç†{processed_count}ä»¶ã€æ›´æ–°{updated_count}ä»¶")
            
            # ç·©å’Œç‰ˆçµ±è¨ˆè¡¨ç¤º
            logger.info(f"æ›´æ–°ç†ç”±åˆ¥çµ±è¨ˆ:")
            for reason, count in self.update_statistics.items():
                if count > 0:
                    logger.info(f"  {reason}: {count}å›")
            
            if self.force_price_detection:
                logger.info(f"ğŸ”„ å¼·åˆ¶æ¤œå‡ºã«ã‚ˆã‚‹æ›´æ–°: {force_updated_count}ä»¶")
            
            if recent_update_count > 0:
                logger.info(f"ğŸ“… æœ€è¿‘ã®æ›´æ–°æ¤œå‡º: {recent_update_count}ä»¶")
            
            if updated_count > 0:
                self.save_history_to_files()
                logger.info(f"âœ… 30åˆ†æ¯ãƒ‡ãƒ¼ã‚¿ + é›†ç´„å±¥æ­´æ›´æ–°å®Œäº†: {updated_count}ã‚¢ã‚¤ãƒ†ãƒ ")
            else:
                if not self.force_price_detection and not self.relaxed_mode:
                    logger.info("ğŸ’¡ ä¾¡æ ¼å¤‰æ›´ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼ˆFORCE_PRICE_DETECTION=true ã‚’è©¦ã—ã¦ãã ã•ã„ï¼‰")
                else:
                    logger.info("âš ï¸ ç·©å’Œè¨­å®šã§ã‚‚æ›´æ–°ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            
            return updated_count
            
        except FileNotFoundError:
            logger.error(f"ä¾¡æ ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.json_file_path}")
            return 0
        except json.JSONDecodeError as e:
            logger.error(f"JSONãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return 0
        except Exception as e:
            logger.error(f"ä¾¡æ ¼å±¥æ­´æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
            return 0

    def generate_chart_data(self, item_id, interval='1hour'):
        """Chart.jsç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆï¼ˆ30åˆ†æ¯ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é›†ç´„ï¼‰"""
        if item_id not in self.price_history:
            return None
        
        if interval not in self.price_history[item_id]:
            return None
        
        history = list(self.price_history[item_id][interval])
        if not history:
            return None
        
        # æ™‚åˆ»ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’é–“éš”ã«å¿œã˜ã¦èª¿æ•´
        def format_time(timestamp_str):
            try:
                timestamp = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
                if interval == '1hour':
                    return timestamp.strftime('%m/%d %H:%M')
                elif interval == '12hour':
                    return timestamp.strftime('%m/%d %H:%M')
                else:  # 1day
                    return timestamp.strftime('%m/%d')
            except:
                return timestamp_str
        
        return {
            'labels': [format_time(point['timestamp']) for point in history],
            'datasets': [{
                'label': f'ä¾¡æ ¼ ({self.price_intervals[interval]["description"]})',
                'data': [point['price'] for point in history],
                'borderColor': '#2c3e50',
                'backgroundColor': 'rgba(44, 62, 80, 0.1)',
                'borderWidth': 2,
                'fill': True,
                'tension': 0.3
            }]
        }

    def export_chart_data_for_web(self, item_id, interval='1hour'):
        """Webç”¨ã«ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›"""
        chart_data = self.generate_chart_data(item_id, interval)
        if not chart_data:
            return False
        
        try:
            chart_file = os.path.join(self.history_dir, f"{item_id}_{interval}.json")
            with open(chart_file, 'w', encoding='utf-8') as f:
                json.dump(chart_data, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            logger.error(f"ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿å‡ºåŠ›ã‚¨ãƒ©ãƒ¼ ({item_id}, {interval}): {e}")
            return False

    def get_statistics(self):
        """å±¥æ­´çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        # 30åˆ†æ¯ç”Ÿãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆ
        raw_data_count = len(self.raw_price_data)
        total_raw_points = sum(len(data) for data in self.raw_price_data.values())
        
        stats = {
            'total_items': len(self.price_history),
            'raw_data_items': raw_data_count,
            'total_raw_data_points': total_raw_points,
            'total_price_raw_points': len(self.total_price_raw_data),
            'intervals': {},
            'configuration': {
                'force_price_detection': self.force_price_detection,
                'relaxed_mode': self.relaxed_mode,
                'time_threshold_ratio': self.time_threshold_ratio,
                'data_collection_interval': '30åˆ†æ¯'
            }
        }
        
        for interval_type, config in self.price_intervals.items():
            item_count = sum(1 for item in self.price_history.values() 
                           if interval_type in item and len(item[interval_type]) > 0)
            total_points = sum(len(item[interval_type]) for item in self.price_history.values() 
                             if interval_type in item)
            
            stats['intervals'][interval_type] = {
                'items_with_data': item_count,
                'total_data_points': total_points,
                'description': config['description'],
                'max_points': config['maxlen'],
                'average_points_per_item': total_points / max(item_count, 1),
                'aggregation_from': f"30åˆ†æ¯ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰{config['aggregation_points']}ãƒã‚¤ãƒ³ãƒˆå¹³å‡"
            }
        
        return stats

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œï¼š30åˆ†æ¯ãƒ‡ãƒ¼ã‚¿åé›†ã¨é›†ç´„å‡¦ç†"""
    logger.info("=" * 50)
    logger.info("MapleStoryä¾¡æ ¼å±¥æ­´æ›´æ–°é–‹å§‹ï¼ˆ30åˆ†æ¯ãƒ‡ãƒ¼ã‚¿é›†ç´„ç‰ˆï¼‰")
    logger.info("=" * 50)
    
    try:
        # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        logger.info("30åˆ†æ¯ãƒ‡ãƒ¼ã‚¿é›†ç´„ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–: data/price_history")
        tracker = HistoricalPriceTracker()
        
        # ç¾åœ¨ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å±¥æ­´æ›´æ–°
        updated = tracker.update_from_current_prices()
        
        # çµ±è¨ˆè¡¨ç¤º
        stats = tracker.get_statistics()
        logger.info(f"ğŸ“Š 30åˆ†æ¯ãƒ‡ãƒ¼ã‚¿é›†ç´„çµ±è¨ˆ:")
        logger.info(f"  ç·ã‚¢ã‚¤ãƒ†ãƒ æ•°: {stats['total_items']}")
        logger.info(f"  30åˆ†æ¯ç”Ÿãƒ‡ãƒ¼ã‚¿: {stats['raw_data_items']}ã‚¢ã‚¤ãƒ†ãƒ ã€{stats['total_raw_data_points']}ãƒã‚¤ãƒ³ãƒˆ")
        logger.info(f"  ç·ä¾¡æ ¼30åˆ†æ¯ãƒ‡ãƒ¼ã‚¿: {stats['total_price_raw_points']}ãƒã‚¤ãƒ³ãƒˆ")
        logger.info(f"  è¨­å®š: å¼·åˆ¶æ¤œå‡º={stats['configuration']['force_price_detection']}, ç·©å’Œãƒ¢ãƒ¼ãƒ‰={stats['configuration']['relaxed_mode']}")
        
        for interval, data in stats['intervals'].items():
            logger.info(f"  {interval}: {data['items_with_data']}ä»¶ ({data['description']}) - {data['total_data_points']}ãƒã‚¤ãƒ³ãƒˆ")
            logger.info(f"    é›†ç´„æ–¹æ³•: {data['aggregation_from']}")
        
        # ç·©å’Œç‰ˆçµæœè¡¨ç¤º
        if tracker.force_price_detection or tracker.relaxed_mode:
            logger.info(f"ğŸ”„ 30åˆ†æ¯ãƒ‡ãƒ¼ã‚¿é›†ç´„çµæœ: {updated}ã‚¢ã‚¤ãƒ†ãƒ æ›´æ–°")
        
        logger.info("=" * 50)
        logger.info(f"âœ… 30åˆ†æ¯ãƒ‡ãƒ¼ã‚¿é›†ç´„æ›´æ–°å®Œäº†: {updated}ã‚¢ã‚¤ãƒ†ãƒ ")
        logger.info("=" * 50)
        
        return updated
        
    except Exception as e:
        logger.error(f"ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        raise

if __name__ == "__main__":
    main()
